{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b748ea6269dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm_utils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99ec438438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " \"'\",\n",
       " '-',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D',\n",
       " 'l',\n",
       " 'c',\n",
       " 'e',\n",
       " 'j',\n",
       " 'M',\n",
       " 'Y',\n",
       " 'p',\n",
       " 'O',\n",
       " 'o',\n",
       " 'm',\n",
       " 'z',\n",
       " 'a',\n",
       " ' ',\n",
       " 'n',\n",
       " 'A',\n",
       " 'v',\n",
       " 'R',\n",
       " 's',\n",
       " 'S',\n",
       " 'd',\n",
       " 'X',\n",
       " 't',\n",
       " 'J',\n",
       " 'P',\n",
       " 'Z',\n",
       " 'F',\n",
       " '-',\n",
       " 'Q',\n",
       " 'K',\n",
       " 'w',\n",
       " 'T',\n",
       " 'k',\n",
       " 'B',\n",
       " 'I',\n",
       " 'L',\n",
       " 'b',\n",
       " 'u',\n",
       " 'N',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'U',\n",
       " 'G',\n",
       " 'r',\n",
       " 'q',\n",
       " 'V',\n",
       " 'y',\n",
       " 'W',\n",
       " 'g',\n",
       " 'C',\n",
       " 'H',\n",
       " 'x',\n",
       " 'f',\n",
       " 'E',\n",
       " 'h',\n",
       " '#']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(set(''.join(names)))\n",
    "x.append('#')\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(''.join(names)))\n",
    "\n",
    "tokens.append(\"#\")\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 13,\n",
       " '#': 55,\n",
       " \"'\": 40,\n",
       " '-': 27,\n",
       " 'A': 15,\n",
       " 'B': 33,\n",
       " 'C': 49,\n",
       " 'D': 0,\n",
       " 'E': 53,\n",
       " 'F': 26,\n",
       " 'G': 42,\n",
       " 'H': 50,\n",
       " 'I': 34,\n",
       " 'J': 23,\n",
       " 'K': 29,\n",
       " 'L': 35,\n",
       " 'M': 5,\n",
       " 'N': 38,\n",
       " 'O': 8,\n",
       " 'P': 24,\n",
       " 'Q': 28,\n",
       " 'R': 17,\n",
       " 'S': 19,\n",
       " 'T': 31,\n",
       " 'U': 41,\n",
       " 'V': 45,\n",
       " 'W': 47,\n",
       " 'X': 21,\n",
       " 'Y': 6,\n",
       " 'Z': 25,\n",
       " 'a': 12,\n",
       " 'b': 36,\n",
       " 'c': 2,\n",
       " 'd': 20,\n",
       " 'e': 3,\n",
       " 'f': 52,\n",
       " 'g': 48,\n",
       " 'h': 54,\n",
       " 'i': 39,\n",
       " 'j': 4,\n",
       " 'k': 32,\n",
       " 'l': 1,\n",
       " 'm': 10,\n",
       " 'n': 14,\n",
       " 'o': 9,\n",
       " 'p': 7,\n",
       " 'q': 44,\n",
       " 'r': 43,\n",
       " 's': 18,\n",
       " 't': 22,\n",
       " 'u': 37,\n",
       " 'v': 16,\n",
       " 'w': 30,\n",
       " 'x': 51,\n",
       " 'y': 46,\n",
       " 'z': 11}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = dict(zip( tokens ,range(n_tokens) ))\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[14 24 29 43  6 43 20 26 55]\n",
      " [14  5 26 33  0 21 55 55 55]\n",
      " [14 41  0 46 27 27 46 20 55]\n",
      " [14  5 46 33 39 43  3  3 20]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-0f96395e9759>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-0f96395e9759>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [1:2]\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(units=64 , activation='tanh')\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(units=56 , activation='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Embedding' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d403e4c43252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membed_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Embedding' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb,h_t])\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(?, 56) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4K6UUnFIg7tSSsUhDe5KKRWH/h8w9WqaecNIAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99a11e26a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Galdhead\n",
      " Comiik\n",
      " Dottes\n",
      " Kevuee\n",
      " Wodie\n",
      " Anril\n",
      " Robjy\n",
      " Klgagoa\n",
      " Ucotela\n",
      " Inbene\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpia\n",
      " Trumpia\n",
      " Trumpy\n",
      " Trumpep\n",
      " Trumpier\n",
      " Trump\n",
      " Trumpiy\n",
      " Trumpy\n",
      " Trumpus\n",
      " Trumpil\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    }
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"jU4Ag2S6J0slu7q7\"\n",
    "COURSERA_EMAIL = \"dhruv.nigam93@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5e002293744f969ca7a2d284562437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
